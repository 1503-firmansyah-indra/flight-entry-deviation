{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2308146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString,box,MultiLineString\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39be696",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"D:/lfv-main-data/data/\"\n",
    "sector_name  = \"sector_67Y\"\n",
    "processed_data_path = \"processed_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9006a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839a8531",
   "metadata": {},
   "source": [
    "# Create Trajectory table\n",
    "create a Geo data frame, with route/trajectory and entry_time into the grid_space relating to a sector. Route and time relates to the oldest flight plan entry of each flight. If trajectory.csv is already present, for the respective folder it will be loaded, created otherwise (this can take a while)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c71e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_frame_dic =  {\"sector_w_esmm\": [13.5,56.5,19,60],\"sector_67Y\":[14,55,22,60]}\n",
    "#TODO enter other sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331577c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = grid_frame_dic[sector_name]\n",
    "grid_frame =  box(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b42c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_format = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "d_format_short = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "class StartsInSectorException(Exception):\n",
    "    pass\n",
    "\n",
    "class NoExitFromSectorException(Exception):\n",
    "    pass\n",
    "\n",
    "class NoIntersectionException(Exception):\n",
    "    pass\n",
    "\n",
    "def get_entry(line, sector):\n",
    "    intersection_line = line.intersection(sector)\n",
    "    if isinstance(intersection_line, MultiLineString):\n",
    "        intersection_line = intersection_line.geoms[0]\n",
    "    intersections = intersection_line.xy\n",
    "    if len(intersections[0]) == 0:\n",
    "        raise NoIntersectionException\n",
    "    entry_lon = intersections[0][0]\n",
    "    entry_lat = intersections[1][0]\n",
    "    return entry_lon, entry_lat\n",
    "\n",
    "def get_entry_time(A,C,A_time_str,C_time_str,B):\n",
    "    time_A = datetime.datetime.strptime(A_time_str,d_format_short) \n",
    "    time_C = datetime.datetime.strptime(C_time_str,d_format_short)\n",
    "    time_B = time_A + datetime.timedelta(seconds=(time_C-time_A).total_seconds() * (A.distance(B) / A.distance(C)))\n",
    "    return time_B.strftime(d_format)\n",
    "\n",
    "def find_first_and_time(route,sector):\n",
    "    points, times = [],[]\n",
    "    for elem in route:\n",
    "        points.append(Point(elem['lon'],elem['lat']))\n",
    "        times.append(elem['eto'])\n",
    "    if sector.contains(points[0]):\n",
    "        return route[0]['lon'], route[0]['lat'],route[0]['eto']\n",
    "    for j,p in enumerate(points[1:]):\n",
    "        i = j-1\n",
    "        line = LineString([points[i-1],p])\n",
    "        if line.intersects(sector):\n",
    "            entry_lon, entry_lat = get_entry(line, sector)\n",
    "            entry_time = get_entry_time(points[i-1],p,times[i-1],times[i],Point(entry_lon, entry_lat))\n",
    "            return entry_lon, entry_lat, entry_time\n",
    "    raise NoIntersectionException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ea196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = []\n",
    "for d in os.listdir(raw_data_path):\n",
    "    folders.append(raw_data_path+d+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abdb9ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/lfv-main-data/data/scat20161015_20161021/\n",
      "293.06481194496155\n",
      "D:/lfv-main-data/data/scat20161112_20161118/\n",
      "568.5924835205078\n",
      "D:/lfv-main-data/data/scat20161210_20161216/\n",
      "842.7559340000153\n",
      "D:/lfv-main-data/data/scat20170107_20170113/\n",
      "1087.296251296997\n",
      "D:/lfv-main-data/data/scat20170215_20170221/\n",
      "1345.6200802326202\n",
      "D:/lfv-main-data/data/scat20170304_20170310/\n",
      "1625.946058511734\n",
      "D:/lfv-main-data/data/scat20170401_20170407/\n",
      "1925.803991317749\n",
      "D:/lfv-main-data/data/scat20170429_20170505/\n",
      "2214.5761110782623\n",
      "D:/lfv-main-data/data/scat20170527_20170602/\n",
      "2530.6361858844757\n",
      "D:/lfv-main-data/data/scat20170624_20170630/\n",
      "2836.3860795497894\n",
      "D:/lfv-main-data/data/scat20170722_20170728/\n",
      "3123.383714199066\n",
      "D:/lfv-main-data/data/scat20170819_20170825/\n",
      "3441.1603519916534\n",
      "D:/lfv-main-data/data/scat20170916_20170922/\n",
      "3771.4143600463867\n"
     ]
    }
   ],
   "source": [
    "if \"trajectories.csv\" not in os.listdir(f\"{processed_data_path}/{sector_name}/intermediate_data/\"):\n",
    "    predicted_trajectories = []\n",
    "    start =  time.time()\n",
    "    for each_folder in folders:\n",
    "        print(each_folder)\n",
    "        for each_file in os.listdir(each_folder):\n",
    "            if each_file in ['airspace.json',\"grib_meteo.json\"]:\n",
    "                continue\n",
    "            with open(each_folder + each_file, 'r') as f:\n",
    "                flight = json.load(f)\n",
    "            if len(flight['predicted_trajectory']) == 0:\n",
    "                continue\n",
    "            ind,pt = 0, flight['predicted_trajectory'][0]\n",
    "            route_lst = []\n",
    "            for p in pt['route']:\n",
    "                route_lst.append(Point(p['lon'],p['lat']))\n",
    "            try:\n",
    "                entry_lon, entry_lat, entry_time = find_first_and_time(pt['route'],grid_frame)\n",
    "            except NoIntersectionException:\n",
    "                continue\n",
    "            predicted_trajectories.append({'flightID':flight['id'], 'time_stamp':pt['time_stamp'], \"entry_time\":entry_time ,\"index\":ind, \n",
    "                                           \"geometry\":LineString(route_lst)})\n",
    "        print(time.time() - start)\n",
    "    crs = 'epsg:4326'\n",
    "    flight_plan_gdf = gpd.GeoDataFrame(predicted_trajectories,crs = crs, geometry=\"geometry\")\n",
    "    flight_plan_gdf.to_csv(f\"{processed_data_path}/{sector_name}/intermediate_data/trajectories.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed6a11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_traj_pd = pd.read_csv(f\"{processed_data_path}/{sector_name}/intermediate_data/trajectories.csv\",index_col=0)\n",
    "pred_traj_pd['geometry'] = pred_traj_pd['geometry'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd7f18",
   "metadata": {},
   "source": [
    "# Trajectory\n",
    "creates matrix for every flight, which represents if a certain grid within the gridspace is ever crossed by the trajectory of a flight (refering to the trajectory.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da8807fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(lon_min, lon_max, lonN, lat_min, lat_max, latN):\n",
    "    lon_step_size = (lon_max - lon_min) / lonN\n",
    "    lat_step_size = (lat_max - lat_min) / latN\n",
    "    tiles = []\n",
    "    lat = lat_max\n",
    "    for i in range(latN):\n",
    "        lon = lon_min\n",
    "        lat_next = lat-lat_step_size\n",
    "        for j in range(lonN):\n",
    "            lon_next = lon+lon_step_size\n",
    "            tiles.append(box(lon, lat, lon_next, lat_next))\n",
    "            lon = lon_next \n",
    "        lat = lat_next\n",
    "    grid_frame = box(lon_min,lat_min,lon_max,lat_max)\n",
    "    return tiles , grid_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da81d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = grid_frame_dic[sector_name]\n",
    "grid_cells,grid_frame = create_grid(a,c,10,b,d,10)\n",
    "crs = 'epsg:4326'\n",
    "grid = gpd.GeoDataFrame(grid_cells, columns=['geometry'], \n",
    "                                 crs=crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc0d528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 78.1 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_trajectory_ts</th>\n",
       "      <th>actual_entry_time</th>\n",
       "      <th>forecasted_entry_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>plt_entry_lon</th>\n",
       "      <th>plt_entry_lat</th>\n",
       "      <th>fp_entry_lon</th>\n",
       "      <th>fp_entry_lat</th>\n",
       "      <th>at_pred_lon</th>\n",
       "      <th>at_pred_lat</th>\n",
       "      <th>entry_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100007</td>\n",
       "      <td>2016-10-20T12:55:56.886000</td>\n",
       "      <td>2016-10-20T13:11:22.00</td>\n",
       "      <td>2016-10-20 13:11:11.777709</td>\n",
       "      <td>2016-10-20T12:56:11.777709</td>\n",
       "      <td>16.196731</td>\n",
       "      <td>57.097328</td>\n",
       "      <td>16.193689</td>\n",
       "      <td>57.096004</td>\n",
       "      <td>16.485511</td>\n",
       "      <td>58.282991</td>\n",
       "      <td>0.236070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100008</td>\n",
       "      <td>2016-10-15T09:05:19.316000</td>\n",
       "      <td>2016-10-15T09:20:43.898437</td>\n",
       "      <td>2016-10-15 09:20:43.207255</td>\n",
       "      <td>2016-10-15T09:05:43.207255</td>\n",
       "      <td>15.639786</td>\n",
       "      <td>56.855186</td>\n",
       "      <td>15.654018</td>\n",
       "      <td>56.861328</td>\n",
       "      <td>16.980937</td>\n",
       "      <td>58.620054</td>\n",
       "      <td>1.105250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100014</td>\n",
       "      <td>2016-10-15T08:15:54.754000</td>\n",
       "      <td>2016-10-15T08:32:23.695312</td>\n",
       "      <td>2016-10-15 08:31:48.503856</td>\n",
       "      <td>2016-10-15T08:16:48.503856</td>\n",
       "      <td>15.485635</td>\n",
       "      <td>56.788660</td>\n",
       "      <td>15.494838</td>\n",
       "      <td>56.792631</td>\n",
       "      <td>16.939137</td>\n",
       "      <td>58.533976</td>\n",
       "      <td>0.715507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100024</td>\n",
       "      <td>2016-10-19T07:39:55.014000</td>\n",
       "      <td>2016-10-19T07:51:38.695312</td>\n",
       "      <td>2016-10-19 07:55:06.351486</td>\n",
       "      <td>2016-10-19T07:40:06.351486</td>\n",
       "      <td>16.018006</td>\n",
       "      <td>57.019585</td>\n",
       "      <td>16.078626</td>\n",
       "      <td>57.045954</td>\n",
       "      <td>16.427790</td>\n",
       "      <td>58.384234</td>\n",
       "      <td>4.708634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100035</td>\n",
       "      <td>2016-10-21T10:23:31.894000</td>\n",
       "      <td>2016-10-21T10:38:37.00</td>\n",
       "      <td>2016-10-21 10:38:45.468653</td>\n",
       "      <td>2016-10-21T10:23:45.468653</td>\n",
       "      <td>16.265025</td>\n",
       "      <td>57.127034</td>\n",
       "      <td>16.269305</td>\n",
       "      <td>57.128896</td>\n",
       "      <td>16.793831</td>\n",
       "      <td>58.232329</td>\n",
       "      <td>0.331944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     predicted_trajectory_ts           actual_entry_time  \\\n",
       "0  100007  2016-10-20T12:55:56.886000      2016-10-20T13:11:22.00   \n",
       "1  100008  2016-10-15T09:05:19.316000  2016-10-15T09:20:43.898437   \n",
       "2  100014  2016-10-15T08:15:54.754000  2016-10-15T08:32:23.695312   \n",
       "3  100024  2016-10-19T07:39:55.014000  2016-10-19T07:51:38.695312   \n",
       "4  100035  2016-10-21T10:23:31.894000      2016-10-21T10:38:37.00   \n",
       "\n",
       "       forecasted_entry_time             prediction_time  plt_entry_lon  \\\n",
       "0 2016-10-20 13:11:11.777709  2016-10-20T12:56:11.777709      16.196731   \n",
       "1 2016-10-15 09:20:43.207255  2016-10-15T09:05:43.207255      15.639786   \n",
       "2 2016-10-15 08:31:48.503856  2016-10-15T08:16:48.503856      15.485635   \n",
       "3 2016-10-19 07:55:06.351486  2016-10-19T07:40:06.351486      16.018006   \n",
       "4 2016-10-21 10:38:45.468653  2016-10-21T10:23:45.468653      16.265025   \n",
       "\n",
       "   plt_entry_lat  fp_entry_lon  fp_entry_lat  at_pred_lon  at_pred_lat  \\\n",
       "0      57.097328     16.193689     57.096004    16.485511    58.282991   \n",
       "1      56.855186     15.654018     56.861328    16.980937    58.620054   \n",
       "2      56.788660     15.494838     56.792631    16.939137    58.533976   \n",
       "3      57.019585     16.078626     57.045954    16.427790    58.384234   \n",
       "4      57.127034     16.269305     57.128896    16.793831    58.232329   \n",
       "\n",
       "   entry_deviation  \n",
       "0         0.236070  \n",
       "1         1.105250  \n",
       "2         0.715507  \n",
       "3         4.708634  \n",
       "4         0.331944  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "filtered_path = f'./{processed_data_path}/{sector_name}/buffer15_combined_results.csv'\n",
    "df_filtered = pd.read_csv(filtered_path)\n",
    "df_filtered['forecasted_entry_time'] = pd.to_datetime(df_filtered['forecasted_entry_time'])\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ids = df_filtered['id'].values\n",
    "\n",
    "pt_gdf = pred_traj_pd.loc[pred_traj_pd['flightID'].isin(relevant_ids)].copy()\n",
    "\n",
    "pt_gdf['time_stamp'] = pd.to_datetime(pt_gdf['time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385bc28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start creating trajectory matrices\n",
      "1308320 has no grid intersection\n",
      "trajectory.csv created\n",
      "CPU times: total: 13.9 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if \"trajectory.csv\" not in os.listdir(f\"{processed_data_path}/{sector_name}/occupancy/\"):\n",
    "    print(\"start creating trajectory matrices\")\n",
    "    pt_occupancies = []\n",
    "    for id_ , flight in df_filtered.iterrows():\n",
    "        this_matrix = np.zeros(len(grid))\n",
    "        if flight['id'] not in pt_gdf['flightID'].values:\n",
    "            pt_occupancies.append(this_matrix)\n",
    "            print(flight['id'],\"has no grid intersection\")\n",
    "            continue\n",
    "        route = pt_gdf.loc[pt_gdf['flightID'] == flight['id']]['geometry'].values[0]\n",
    "        intersections = grid.intersects(route)\n",
    "        this_matrix += intersections\n",
    "        pt_occupancies.append(this_matrix)\n",
    "    colnames = [\"flight_id\"] + list(range(len(grid)))\n",
    "    pt_occ_df = pd.DataFrame(np.insert(pt_occupancies,0,df_filtered['id'].values,axis=1), columns =colnames)\n",
    "    pt_occ_df.to_csv(f\"{processed_data_path}/{sector_name}/occupancy/trajectory.csv\",index=False)\n",
    "    print(\"trajectory.csv created\")\n",
    "    pt_occ_df\n",
    "else:\n",
    "    print(\"trajectory.csv already existend for sector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc392144",
   "metadata": {},
   "source": [
    "# Occupancy\n",
    "Create the occupancy matrixes at different timepoints (see deltas_from_et). Variable refers to minutes after the expected sector entry of a flight.\n",
    "\n",
    "To recreate the matrices ensure that there is an empty folder occupancy/ in the respective processed_data/sector directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa251a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_at_time(trajectory, timestamp):\n",
    "    last_point = None\n",
    "    for point in trajectory:\n",
    "        eto = datetime.datetime.strptime(point['eto'],\"%Y-%m-%dT%H:%M:%S\")\n",
    "        if eto > timestamp and last_point:\n",
    "            last_eto =  datetime.datetime.strptime(last_point['eto'],\"%Y-%m-%dT%H:%M:%S\")\n",
    "            if eto == last_eto:\n",
    "                continue\n",
    "            factor = (timestamp -last_eto).seconds / (eto - last_eto).seconds\n",
    "            res_lon = last_point['lon'] + factor*(point['lon'] - last_point['lon'])\n",
    "            res_lat = last_point['lat'] + factor*(point['lat'] - last_point['lat'])\n",
    "            return Point(res_lon, res_lat)\n",
    "        else:\n",
    "            last_point = point\n",
    "    return None\n",
    "\n",
    "def find_folder(path, file):\n",
    "    for folder in os.listdir(path):\n",
    "        if file in os.listdir(path+folder):\n",
    "            return path+folder+\"/\"\n",
    "    return \"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b9d61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_gdf['entry_time'] = pd.to_datetime(pt_gdf['entry_time'])\n",
    "pt_gdf['time_stamp'] = pd.to_datetime(pt_gdf['time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb313327",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pts_ff = {}\n",
    "for id_ , flight in df_filtered.iterrows():\n",
    "    et = flight['forecasted_entry_time']\n",
    "    possible_pt = pt_gdf.loc[(pt_gdf['entry_time'] > et - datetime.timedelta(minutes = 30)) \n",
    "                             & (pt_gdf['entry_time'] < et + datetime.timedelta(minutes = 30))\n",
    "                            # & (pt_gdf['time_stamp'] < et - timedelta(minutes = buffer))\n",
    "                            & (pt_gdf['flightID'] != flight['id'])]\n",
    "    most_recent_ones = possible_pt.groupby(\"flightID\", as_index = False).max(\"time_stamp\").reset_index()\n",
    "    relevant_pts_ff[flight['id']] = most_recent_ones['flightID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ce05e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start creating occupancy matrices\n",
      "7.71902740254728 %\n",
      "15.43805480509456 %\n",
      "23.15708220764184 %\n",
      "30.87610961018912 %\n",
      "38.595137012736394 %\n",
      "46.31416441528368 %\n",
      "54.033191817830954 %\n",
      "61.75221922037824 %\n",
      "69.4712466229255 %\n",
      "77.19027402547279 %\n",
      "84.90930142802007 %\n",
      "92.62832883056736 %\n",
      "finished creating occupancy matrices\n"
     ]
    }
   ],
   "source": [
    "video_occ_path = f\"{processed_data_path}/{sector_name}/occupancy/\"\n",
    "deltas_from_et = [0,5,10]\n",
    "\n",
    "if \"occs\" not in os.listdir(video_occ_path):\n",
    "    print(\"start creating occupancy matrices\")\n",
    "    os.mkdir(f\"{video_occ_path}occs\")\n",
    "    c = 0\n",
    "    point_delta_dict = {}\n",
    "    for id_ , flight in df_filtered.iterrows():\n",
    "        c+=1\n",
    "        folder_path = find_folder(raw_data_path, str(flight['id']) + \".json\")\n",
    "        entry_time = flight['forecasted_entry_time']\n",
    "        point_delta_dict[flight['id']] = {}\n",
    "        for fid_pt in relevant_pts_ff[flight['id']]:\n",
    "            point_delta_dict[flight['id']][fid_pt] = {}\n",
    "            with open(folder_path+ str(fid_pt) +\".json\", 'r') as f:\n",
    "                flight_json = json.load(f)\n",
    "            pt_route = flight_json['predicted_trajectory'][0]['route']\n",
    "            for delta in deltas_from_et:\n",
    "                point = point_at_time(pt_route, entry_time + datetime.timedelta(minutes=delta))\n",
    "                point_delta_dict[flight['id']][fid_pt][delta] = point\n",
    "        if (c%1000)==0:\n",
    "            print(c/len(df_filtered) * 100, \"%\")\n",
    "            all_occs = []\n",
    "            for fid, point_dict in point_delta_dict.items():\n",
    "                occs = []\n",
    "                for delta in deltas_from_et:\n",
    "                    this_delta_occ = np.zeros(100)\n",
    "                    for pt_ids,delta_dict in point_dict.items():\n",
    "                        if delta_dict[delta]:\n",
    "                            this_delta_occ += grid.intersects(delta_dict[delta])\n",
    "                    occs.append(this_delta_occ)\n",
    "                all_occs.append(occs)\n",
    "            all_occs = np.array(all_occs)\n",
    "            np.save(video_occ_path+\"occs/\"+str(c/1000),all_occs)\n",
    "            point_delta_dict = {}\n",
    "    all_occs = []\n",
    "    for fid, point_dict in point_delta_dict.items():\n",
    "        occs = []\n",
    "        for delta in deltas_from_et:\n",
    "            this_delta_occ = np.zeros(100)\n",
    "            for pt_ids,delta_dict in point_dict.items():\n",
    "                if delta_dict[delta]:\n",
    "                    this_delta_occ += grid.intersects(delta_dict[delta])\n",
    "            occs.append(this_delta_occ)\n",
    "        all_occs.append(occs)\n",
    "    all_occs = np.array(all_occs)\n",
    "    np.save(video_occ_path+\"occs/\"+f\"{int(len(df_filtered)//1000)+1}.0\",all_occs)\n",
    "    np.save(video_occ_path+\"ids\", df_filtered['id'].values)\n",
    "    print(\"finished creating occupancy matrices\")\n",
    "else:\n",
    "    print(\"occupancy matrices already exist for the sector. To recreate, delete occs and ids folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada0624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
