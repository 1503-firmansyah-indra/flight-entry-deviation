{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2308146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString,box,MultiLineString\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39be696",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"raw_data/\"\n",
    "#sector_name  = \"sector_67Y\"\n",
    "sector_name = \"sector_w_esmm\"\n",
    "processed_data_path = \"processed_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9006a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839a8531",
   "metadata": {},
   "source": [
    "# Create Trajectory table\n",
    "create a Geo data frame, with route/trajectory and entry_time into the grid_space relating to a sector. Route and time relates to the oldest flight plan entry of each flight. If trajectory.csv is already present, for the respective folder it will be loaded, created otherwise (this can take a while)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c71e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_frame_dic =  {\"sector_w_esmm\": [13.5,56.5,19,60],\"sector_67Y\":[14,55,22,60]}\n",
    "#TODO enter other sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331577c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = grid_frame_dic[sector_name]\n",
    "grid_frame =  box(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b42c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_format = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "d_format_short = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "class StartsInSectorException(Exception):\n",
    "    pass\n",
    "\n",
    "class NoExitFromSectorException(Exception):\n",
    "    pass\n",
    "\n",
    "class NoIntersectionException(Exception):\n",
    "    pass\n",
    "\n",
    "def get_entry(line, sector):\n",
    "    intersection_line = line.intersection(sector)\n",
    "    if isinstance(intersection_line, MultiLineString):\n",
    "        intersection_line = intersection_line.geoms[0]\n",
    "    intersections = intersection_line.xy\n",
    "    if len(intersections[0]) == 0:\n",
    "        raise NoIntersectionException\n",
    "    entry_lon = intersections[0][0]\n",
    "    entry_lat = intersections[1][0]\n",
    "    return entry_lon, entry_lat\n",
    "\n",
    "def get_entry_time(A,C,A_time_str,C_time_str,B):\n",
    "    time_A = datetime.datetime.strptime(A_time_str,d_format_short) \n",
    "    time_C = datetime.datetime.strptime(C_time_str,d_format_short)\n",
    "    time_B = time_A + datetime.timedelta(seconds=(time_C-time_A).total_seconds() * (A.distance(B) / A.distance(C)))\n",
    "    return time_B.strftime(d_format)\n",
    "\n",
    "def find_first_and_time(route,sector):\n",
    "    points, times = [],[]\n",
    "    for elem in route:\n",
    "        points.append(Point(elem['lon'],elem['lat']))\n",
    "        times.append(elem['eto'])\n",
    "    if sector.contains(points[0]):\n",
    "        return route[0]['lon'], route[0]['lat'],route[0]['eto']\n",
    "    for j,p in enumerate(points[1:]):\n",
    "        i = j-1\n",
    "        line = LineString([points[i-1],p])\n",
    "        if line.intersects(sector):\n",
    "            entry_lon, entry_lat = get_entry(line, sector)\n",
    "            entry_time = get_entry_time(points[i-1],p,times[i-1],times[i],Point(entry_lon, entry_lat))\n",
    "            return entry_lon, entry_lat, entry_time\n",
    "    raise NoIntersectionException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ea196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = []\n",
    "for d in os.listdir(raw_data_path):\n",
    "    if not d.endswith('.zip') and d != 'sectors_info':\n",
    "        folders.append(raw_data_path+d+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae3b6af-2b6e-4e32-a17b-416c324561b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data/scat20161015_20161021/',\n",
       " 'raw_data/scat20161112_20161118/',\n",
       " 'raw_data/scat20161210_20161216/',\n",
       " 'raw_data/scat20170107_20170113/',\n",
       " 'raw_data/scat20170215_20170221/',\n",
       " 'raw_data/scat20170304_20170310/',\n",
       " 'raw_data/scat20170401_20170407/',\n",
       " 'raw_data/scat20170429_20170505/',\n",
       " 'raw_data/scat20170527_20170602/',\n",
       " 'raw_data/scat20170624_20170630/',\n",
       " 'raw_data/scat20170722_20170728/',\n",
       " 'raw_data/scat20170819_20170825/',\n",
       " 'raw_data/scat20170916_20170922/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbab5ec-b57c-4de5-95f3-1c83bf2a1c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb9ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/scat20161015_20161021/\n",
      "424.9291591644287\n",
      "raw_data/scat20161112_20161118/\n",
      "798.3067941665649\n",
      "raw_data/scat20161210_20161216/\n"
     ]
    }
   ],
   "source": [
    "if \"trajectories.csv\" not in os.listdir(f\"{processed_data_path}/{sector_name}/intermediate_data/\"):\n",
    "    predicted_trajectories = []\n",
    "    start =  time.time()\n",
    "    for each_folder in folders:\n",
    "        print(each_folder)\n",
    "        for each_file in os.listdir(each_folder):\n",
    "            if each_file in ['airspace.json',\"grib_meteo.json\"]:\n",
    "                continue\n",
    "            with open(each_folder + each_file, 'r') as f:\n",
    "                flight = json.load(f)\n",
    "            if len(flight['predicted_trajectory']) == 0:\n",
    "                continue\n",
    "            ind,pt = 0, flight['predicted_trajectory'][0]\n",
    "            route_lst = []\n",
    "            for p in pt['route']:\n",
    "                route_lst.append(Point(p['lon'],p['lat']))\n",
    "            try:\n",
    "                entry_lon, entry_lat, entry_time = find_first_and_time(pt['route'],grid_frame)\n",
    "            except NoIntersectionException:\n",
    "                continue\n",
    "            predicted_trajectories.append({'flightID':flight['id'], 'time_stamp':pt['time_stamp'], \"entry_time\":entry_time ,\"index\":ind, \n",
    "                                           \"geometry\":LineString(route_lst)})\n",
    "        print(time.time() - start)\n",
    "    crs = 'epsg:4326'\n",
    "    flight_plan_gdf = gpd.GeoDataFrame(predicted_trajectories,crs = crs, geometry=\"geometry\")\n",
    "    flight_plan_gdf.to_csv(f\"{processed_data_path}/{sector_name}/intermediate_data/trajectories.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_traj_pd = pd.read_csv(f\"{processed_data_path}/{sector_name}/intermediate_data/trajectories.csv\",index_col=0)\n",
    "pred_traj_pd['geometry'] = pred_traj_pd['geometry'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd7f18",
   "metadata": {},
   "source": [
    "# Trajectory\n",
    "creates matrix for every flight, which represents if a certain grid within the gridspace is ever crossed by the trajectory of a flight (refering to the trajectory.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8807fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(lon_min, lon_max, lonN, lat_min, lat_max, latN):\n",
    "    lon_step_size = (lon_max - lon_min) / lonN\n",
    "    lat_step_size = (lat_max - lat_min) / latN\n",
    "    tiles = []\n",
    "    lat = lat_max\n",
    "    for i in range(latN):\n",
    "        lon = lon_min\n",
    "        lat_next = lat-lat_step_size\n",
    "        for j in range(lonN):\n",
    "            lon_next = lon+lon_step_size\n",
    "            tiles.append(box(lon, lat, lon_next, lat_next))\n",
    "            lon = lon_next \n",
    "        lat = lat_next\n",
    "    grid_frame = box(lon_min,lat_min,lon_max,lat_max)\n",
    "    return tiles , grid_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da81d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = grid_frame_dic[sector_name]\n",
    "grid_cells,grid_frame = create_grid(a,c,10,b,d,10)\n",
    "crs = 'epsg:4326'\n",
    "grid = gpd.GeoDataFrame(grid_cells, columns=['geometry'], \n",
    "                                 crs=crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filtered_path = f'./{processed_data_path}{sector_name}/sector_{sector_name}_buffer15_combined_results.csv'\n",
    "df_filtered = pd.read_csv(filtered_path)\n",
    "df_filtered['forecasted_entry_time'] = pd.to_datetime(df_filtered['forecasted_entry_time'])\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ids = df_filtered['id'].values\n",
    "\n",
    "pt_gdf = pred_traj_pd.loc[pred_traj_pd['flightID'].isin(relevant_ids)].copy()\n",
    "\n",
    "pt_gdf['time_stamp'] = pd.to_datetime(pt_gdf['time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385bc28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if \"trajectory.csv\" not in os.listdir(f\"{processed_data_path}/{sector_name}/occupancy/\"):\n",
    "    print(\"start creating trajectory matrices\")\n",
    "    pt_occupancies = []\n",
    "    for id_ , flight in df_filtered.iterrows():\n",
    "        this_matrix = np.zeros(len(grid))\n",
    "        if flight['id'] not in pt_gdf['flightID'].values:\n",
    "            pt_occupancies.append(this_matrix)\n",
    "            print(flight['id'],\"has no grid intersection\")\n",
    "            continue\n",
    "        route = pt_gdf.loc[pt_gdf['flightID'] == flight['id']]['geometry'].values[0]\n",
    "        intersections = grid.intersects(route)\n",
    "        this_matrix += intersections\n",
    "        pt_occupancies.append(this_matrix)\n",
    "    colnames = [\"flight_id\"] + list(range(len(grid)))\n",
    "    pt_occ_df = pd.DataFrame(np.insert(pt_occupancies,0,df_filtered['id'].values,axis=1), columns =colnames)\n",
    "    pt_occ_df.to_csv(f\"{processed_data_path}/{sector_name}/occupancy/trajectory.csv\",index=False)\n",
    "    print(\"trajectory.csv created\")\n",
    "    pt_occ_df\n",
    "else:\n",
    "    print(\"trajectory.csv already existend for sector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc392144",
   "metadata": {},
   "source": [
    "# Occupancy\n",
    "Create the occupancy matrixes at different timepoints (see deltas_from_et). Variable refers to minutes after the expected sector entry of a flight.\n",
    "\n",
    "To recreate the matrices ensure that there is an empty folder occupancy/ in the respective processed_data/sector directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa251a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_at_time(trajectory, timestamp):\n",
    "    last_point = None\n",
    "    for point in trajectory:\n",
    "        eto = datetime.datetime.strptime(point['eto'],\"%Y-%m-%dT%H:%M:%S\")\n",
    "        if eto > timestamp and last_point:\n",
    "            last_eto =  datetime.datetime.strptime(last_point['eto'],\"%Y-%m-%dT%H:%M:%S\")\n",
    "            if eto == last_eto:\n",
    "                continue\n",
    "            factor = (timestamp -last_eto).seconds / (eto - last_eto).seconds\n",
    "            res_lon = last_point['lon'] + factor*(point['lon'] - last_point['lon'])\n",
    "            res_lat = last_point['lat'] + factor*(point['lat'] - last_point['lat'])\n",
    "            return Point(res_lon, res_lat)\n",
    "        else:\n",
    "            last_point = point\n",
    "    return None\n",
    "\n",
    "def find_folder(path, file):\n",
    "    for folder in os.listdir(path):\n",
    "        if not folder.endswith('.zip'):\n",
    "            if file in os.listdir(path+folder):\n",
    "                return path+folder+\"/\"\n",
    "    return \"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_gdf['entry_time'] = pd.to_datetime(pt_gdf['entry_time'])\n",
    "pt_gdf['time_stamp'] = pd.to_datetime(pt_gdf['time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb313327",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pts_ff = {}\n",
    "for id_ , flight in df_filtered.iterrows():\n",
    "    et = flight['forecasted_entry_time']\n",
    "    possible_pt = pt_gdf.loc[(pt_gdf['entry_time'] > et - datetime.timedelta(minutes = 30)) \n",
    "                             & (pt_gdf['entry_time'] < et + datetime.timedelta(minutes = 30))\n",
    "                            # & (pt_gdf['time_stamp'] < et - timedelta(minutes = buffer))\n",
    "                            & (pt_gdf['flightID'] != flight['id'])]\n",
    "    most_recent_ones = possible_pt.groupby(\"flightID\", as_index = False).max(\"time_stamp\").reset_index()\n",
    "    relevant_pts_ff[flight['id']] = most_recent_ones['flightID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce05e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_occ_path = f\"{processed_data_path}/{sector_name}/occupancy/\"\n",
    "deltas_from_et = [0,5,10]\n",
    "\n",
    "if \"occs\" not in os.listdir(video_occ_path):\n",
    "    print(\"start creating occupancy matrices\")\n",
    "    os.mkdir(f\"{video_occ_path}occs\")\n",
    "    c = 0\n",
    "    point_delta_dict = {}\n",
    "    for id_ , flight in df_filtered.iterrows():\n",
    "        c+=1\n",
    "        folder_path = find_folder(raw_data_path, str(flight['id']) + \".json\")\n",
    "        entry_time = flight['forecasted_entry_time']\n",
    "        point_delta_dict[flight['id']] = {}\n",
    "        for fid_pt in relevant_pts_ff[flight['id']]:\n",
    "            point_delta_dict[flight['id']][fid_pt] = {}\n",
    "            with open(folder_path+ str(fid_pt) +\".json\", 'r') as f:\n",
    "                flight_json = json.load(f)\n",
    "            pt_route = flight_json['predicted_trajectory'][0]['route']\n",
    "            for delta in deltas_from_et:\n",
    "                point = point_at_time(pt_route, entry_time + datetime.timedelta(minutes=delta))\n",
    "                point_delta_dict[flight['id']][fid_pt][delta] = point\n",
    "        if (c%1000)==0:\n",
    "            print(c/len(df_filtered) * 100, \"%\")\n",
    "            all_occs = []\n",
    "            for fid, point_dict in point_delta_dict.items():\n",
    "                occs = []\n",
    "                for delta in deltas_from_et:\n",
    "                    this_delta_occ = np.zeros(100)\n",
    "                    for pt_ids,delta_dict in point_dict.items():\n",
    "                        if delta_dict[delta]:\n",
    "                            this_delta_occ += grid.intersects(delta_dict[delta])\n",
    "                    occs.append(this_delta_occ)\n",
    "                all_occs.append(occs)\n",
    "            all_occs = np.array(all_occs)\n",
    "            np.save(video_occ_path+\"occs/\"+str(c/1000),all_occs)\n",
    "            point_delta_dict = {}\n",
    "    all_occs = []\n",
    "    for fid, point_dict in point_delta_dict.items():\n",
    "        occs = []\n",
    "        for delta in deltas_from_et:\n",
    "            this_delta_occ = np.zeros(100)\n",
    "            for pt_ids,delta_dict in point_dict.items():\n",
    "                if delta_dict[delta]:\n",
    "                    this_delta_occ += grid.intersects(delta_dict[delta])\n",
    "            occs.append(this_delta_occ)\n",
    "        all_occs.append(occs)\n",
    "    all_occs = np.array(all_occs)\n",
    "    np.save(video_occ_path+\"occs/\"+f\"{int(len(df_filtered)//1000)+1}.0\",all_occs)\n",
    "    np.save(video_occ_path+\"ids\", df_filtered['id'].values)\n",
    "    print(\"finished creating occupancy matrices\")\n",
    "else:\n",
    "    print(\"occupancy matrices already exist for the sector. To recreate, delete occs and ids folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada0624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab41e8e-c502-43bb-be46-6e3e15744095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
