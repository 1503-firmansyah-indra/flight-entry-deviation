{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2308146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString,box,MultiLineString\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39be696",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"raw_data/\"\n",
    "#sector_name  = \"sector_67Y\"\n",
    "sector_name = \"sector_w_esmm\"\n",
    "processed_data_path = \"processed_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9006a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839a8531",
   "metadata": {},
   "source": [
    "# Create Trajectory table\n",
    "create a Geo data frame, with route/trajectory and entry_time into the grid_space relating to a sector. Route and time relates to the oldest flight plan entry of each flight. If trajectory.csv is already present, for the respective folder it will be loaded, created otherwise (this can take a while)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c71e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_frame_dic =  {\"sector_w_esmm\": [13.5,56.5,19,60],\"sector_67Y\":[14,55,22,60]}\n",
    "#TODO enter other sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331577c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = grid_frame_dic[sector_name]\n",
    "grid_frame =  box(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b42c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_format = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "d_format_short = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "class StartsInSectorException(Exception):\n",
    "    pass\n",
    "\n",
    "class NoExitFromSectorException(Exception):\n",
    "    pass\n",
    "\n",
    "class NoIntersectionException(Exception):\n",
    "    pass\n",
    "\n",
    "def get_entry(line, sector):\n",
    "    intersection_line = line.intersection(sector)\n",
    "    if isinstance(intersection_line, MultiLineString):\n",
    "        intersection_line = intersection_line.geoms[0]\n",
    "    intersections = intersection_line.xy\n",
    "    if len(intersections[0]) == 0:\n",
    "        raise NoIntersectionException\n",
    "    entry_lon = intersections[0][0]\n",
    "    entry_lat = intersections[1][0]\n",
    "    return entry_lon, entry_lat\n",
    "\n",
    "def get_entry_time(A,C,A_time_str,C_time_str,B):\n",
    "    time_A = datetime.datetime.strptime(A_time_str,d_format_short) \n",
    "    time_C = datetime.datetime.strptime(C_time_str,d_format_short)\n",
    "    time_B = time_A + datetime.timedelta(seconds=(time_C-time_A).total_seconds() * (A.distance(B) / A.distance(C)))\n",
    "    return time_B.strftime(d_format)\n",
    "\n",
    "def find_first_and_time(route,sector):\n",
    "    points, times = [],[]\n",
    "    for elem in route:\n",
    "        points.append(Point(elem['lon'],elem['lat']))\n",
    "        times.append(elem['eto'])\n",
    "    if sector.contains(points[0]):\n",
    "        return route[0]['lon'], route[0]['lat'],route[0]['eto']\n",
    "    for j,p in enumerate(points[1:]):\n",
    "        i = j-1\n",
    "        line = LineString([points[i-1],p])\n",
    "        if line.intersects(sector):\n",
    "            entry_lon, entry_lat = get_entry(line, sector)\n",
    "            entry_time = get_entry_time(points[i-1],p,times[i-1],times[i],Point(entry_lon, entry_lat))\n",
    "            return entry_lon, entry_lat, entry_time\n",
    "    raise NoIntersectionException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ea196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = []\n",
    "for d in os.listdir(raw_data_path):\n",
    "    if not d.endswith('.zip') and d != 'sectors_info':\n",
    "        folders.append(raw_data_path+d+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae3b6af-2b6e-4e32-a17b-416c324561b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data/scat20161015_20161021/',\n",
       " 'raw_data/scat20161112_20161118/',\n",
       " 'raw_data/scat20161210_20161216/',\n",
       " 'raw_data/scat20170107_20170113/',\n",
       " 'raw_data/scat20170215_20170221/',\n",
       " 'raw_data/scat20170304_20170310/',\n",
       " 'raw_data/scat20170401_20170407/',\n",
       " 'raw_data/scat20170429_20170505/',\n",
       " 'raw_data/scat20170527_20170602/',\n",
       " 'raw_data/scat20170624_20170630/',\n",
       " 'raw_data/scat20170722_20170728/',\n",
       " 'raw_data/scat20170819_20170825/',\n",
       " 'raw_data/scat20170916_20170922/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbab5ec-b57c-4de5-95f3-1c83bf2a1c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdb9ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/scat20161015_20161021/\n",
      "424.9291591644287\n",
      "raw_data/scat20161112_20161118/\n",
      "798.3067941665649\n",
      "raw_data/scat20161210_20161216/\n",
      "1635.1222078800201\n",
      "raw_data/scat20170107_20170113/\n",
      "1880.855153799057\n",
      "raw_data/scat20170215_20170221/\n",
      "2141.2517206668854\n",
      "raw_data/scat20170304_20170310/\n",
      "2424.3372168540955\n",
      "raw_data/scat20170401_20170407/\n",
      "2731.20641040802\n",
      "raw_data/scat20170429_20170505/\n",
      "3016.1796345710754\n",
      "raw_data/scat20170527_20170602/\n",
      "3655.6356797218323\n",
      "raw_data/scat20170624_20170630/\n",
      "4069.811628341675\n",
      "raw_data/scat20170722_20170728/\n",
      "4472.317538738251\n",
      "raw_data/scat20170819_20170825/\n",
      "4932.861466407776\n",
      "raw_data/scat20170916_20170922/\n",
      "5403.051256895065\n"
     ]
    }
   ],
   "source": [
    "if \"trajectories.csv\" not in os.listdir(f\"{processed_data_path}/{sector_name}/intermediate_data/\"):\n",
    "    predicted_trajectories = []\n",
    "    start =  time.time()\n",
    "    for each_folder in folders:\n",
    "        print(each_folder)\n",
    "        for each_file in os.listdir(each_folder):\n",
    "            if each_file in ['airspace.json',\"grib_meteo.json\"]:\n",
    "                continue\n",
    "            with open(each_folder + each_file, 'r') as f:\n",
    "                flight = json.load(f)\n",
    "            if len(flight['predicted_trajectory']) == 0:\n",
    "                continue\n",
    "            ind,pt = 0, flight['predicted_trajectory'][0]\n",
    "            route_lst = []\n",
    "            for p in pt['route']:\n",
    "                route_lst.append(Point(p['lon'],p['lat']))\n",
    "            try:\n",
    "                entry_lon, entry_lat, entry_time = find_first_and_time(pt['route'],grid_frame)\n",
    "            except NoIntersectionException:\n",
    "                continue\n",
    "            predicted_trajectories.append({'flightID':flight['id'], 'time_stamp':pt['time_stamp'], \"entry_time\":entry_time ,\"index\":ind, \n",
    "                                           \"geometry\":LineString(route_lst)})\n",
    "        print(time.time() - start)\n",
    "    crs = 'epsg:4326'\n",
    "    flight_plan_gdf = gpd.GeoDataFrame(predicted_trajectories,crs = crs, geometry=\"geometry\")\n",
    "    flight_plan_gdf.to_csv(f\"{processed_data_path}/{sector_name}/intermediate_data/trajectories.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6a11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_traj_pd = pd.read_csv(f\"{processed_data_path}/{sector_name}/intermediate_data/trajectories.csv\",index_col=0)\n",
    "pred_traj_pd['geometry'] = pred_traj_pd['geometry'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd7f18",
   "metadata": {},
   "source": [
    "# Trajectory\n",
    "creates matrix for every flight, which represents if a certain grid within the gridspace is ever crossed by the trajectory of a flight (refering to the trajectory.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8807fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(lon_min, lon_max, lonN, lat_min, lat_max, latN):\n",
    "    lon_step_size = (lon_max - lon_min) / lonN\n",
    "    lat_step_size = (lat_max - lat_min) / latN\n",
    "    tiles = []\n",
    "    lat = lat_max\n",
    "    for i in range(latN):\n",
    "        lon = lon_min\n",
    "        lat_next = lat-lat_step_size\n",
    "        for j in range(lonN):\n",
    "            lon_next = lon+lon_step_size\n",
    "            tiles.append(box(lon, lat, lon_next, lat_next))\n",
    "            lon = lon_next \n",
    "        lat = lat_next\n",
    "    grid_frame = box(lon_min,lat_min,lon_max,lat_max)\n",
    "    return tiles , grid_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da81d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = grid_frame_dic[sector_name]\n",
    "grid_cells,grid_frame = create_grid(a,c,10,b,d,10)\n",
    "crs = 'epsg:4326'\n",
    "grid = gpd.GeoDataFrame(grid_cells, columns=['geometry'], \n",
    "                                 crs=crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc0d528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 224 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_trajectory_ts</th>\n",
       "      <th>actual_entry_time</th>\n",
       "      <th>forecasted_entry_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>plt_entry_lon</th>\n",
       "      <th>plt_entry_lat</th>\n",
       "      <th>fp_entry_lon</th>\n",
       "      <th>fp_entry_lat</th>\n",
       "      <th>at_pred_lon</th>\n",
       "      <th>at_pred_lat</th>\n",
       "      <th>entry_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>2016-10-20T19:33:13.914000</td>\n",
       "      <td>2016-10-20T19:49:03.898437</td>\n",
       "      <td>2016-10-20 19:48:37.086194</td>\n",
       "      <td>2016-10-20T19:33:37.086194</td>\n",
       "      <td>15.402479</td>\n",
       "      <td>57.226737</td>\n",
       "      <td>15.408764</td>\n",
       "      <td>57.223158</td>\n",
       "      <td>13.267107</td>\n",
       "      <td>55.698549</td>\n",
       "      <td>0.550407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100009</td>\n",
       "      <td>2016-10-16T12:53:23.931000</td>\n",
       "      <td>2016-10-16T13:08:54.093750</td>\n",
       "      <td>2016-10-16 13:09:22.733682</td>\n",
       "      <td>2016-10-16T12:54:22.733682</td>\n",
       "      <td>15.292028</td>\n",
       "      <td>57.289634</td>\n",
       "      <td>15.266457</td>\n",
       "      <td>57.304196</td>\n",
       "      <td>13.131639</td>\n",
       "      <td>55.932303</td>\n",
       "      <td>2.237535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100012</td>\n",
       "      <td>2016-10-19T19:10:22.579000</td>\n",
       "      <td>2016-10-19T19:26:29.296875</td>\n",
       "      <td>2016-10-19 19:26:05.576465</td>\n",
       "      <td>2016-10-19T19:11:05.576465</td>\n",
       "      <td>16.895720</td>\n",
       "      <td>57.406507</td>\n",
       "      <td>16.903628</td>\n",
       "      <td>57.410547</td>\n",
       "      <td>15.719317</td>\n",
       "      <td>55.563499</td>\n",
       "      <td>0.654471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100016</td>\n",
       "      <td>2016-10-20T20:44:09.172000</td>\n",
       "      <td>2016-10-20T20:59:23.898437</td>\n",
       "      <td>2016-10-20 20:59:23.719499</td>\n",
       "      <td>2016-10-20T20:44:23.719499</td>\n",
       "      <td>14.898149</td>\n",
       "      <td>57.513930</td>\n",
       "      <td>14.898420</td>\n",
       "      <td>57.513776</td>\n",
       "      <td>12.229291</td>\n",
       "      <td>56.407703</td>\n",
       "      <td>0.023667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100020</td>\n",
       "      <td>2016-10-18T10:04:23.831000</td>\n",
       "      <td>2016-10-18T10:19:48.695312</td>\n",
       "      <td>2016-10-18 10:19:50.148890</td>\n",
       "      <td>2016-10-18T10:04:50.148890</td>\n",
       "      <td>15.399915</td>\n",
       "      <td>57.228198</td>\n",
       "      <td>15.403606</td>\n",
       "      <td>57.226096</td>\n",
       "      <td>13.211440</td>\n",
       "      <td>55.661244</td>\n",
       "      <td>0.323228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     predicted_trajectory_ts           actual_entry_time  \\\n",
       "0  100002  2016-10-20T19:33:13.914000  2016-10-20T19:49:03.898437   \n",
       "1  100009  2016-10-16T12:53:23.931000  2016-10-16T13:08:54.093750   \n",
       "2  100012  2016-10-19T19:10:22.579000  2016-10-19T19:26:29.296875   \n",
       "3  100016  2016-10-20T20:44:09.172000  2016-10-20T20:59:23.898437   \n",
       "4  100020  2016-10-18T10:04:23.831000  2016-10-18T10:19:48.695312   \n",
       "\n",
       "       forecasted_entry_time             prediction_time  plt_entry_lon  \\\n",
       "0 2016-10-20 19:48:37.086194  2016-10-20T19:33:37.086194      15.402479   \n",
       "1 2016-10-16 13:09:22.733682  2016-10-16T12:54:22.733682      15.292028   \n",
       "2 2016-10-19 19:26:05.576465  2016-10-19T19:11:05.576465      16.895720   \n",
       "3 2016-10-20 20:59:23.719499  2016-10-20T20:44:23.719499      14.898149   \n",
       "4 2016-10-18 10:19:50.148890  2016-10-18T10:04:50.148890      15.399915   \n",
       "\n",
       "   plt_entry_lat  fp_entry_lon  fp_entry_lat  at_pred_lon  at_pred_lat  \\\n",
       "0      57.226737     15.408764     57.223158    13.267107    55.698549   \n",
       "1      57.289634     15.266457     57.304196    13.131639    55.932303   \n",
       "2      57.406507     16.903628     57.410547    15.719317    55.563499   \n",
       "3      57.513930     14.898420     57.513776    12.229291    56.407703   \n",
       "4      57.228198     15.403606     57.226096    13.211440    55.661244   \n",
       "\n",
       "   entry_deviation  \n",
       "0         0.550407  \n",
       "1         2.237535  \n",
       "2         0.654471  \n",
       "3         0.023667  \n",
       "4         0.323228  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "filtered_path = f'./{processed_data_path}{sector_name}/sector_{sector_name}_buffer15_combined_results.csv'\n",
    "df_filtered = pd.read_csv(filtered_path)\n",
    "df_filtered['forecasted_entry_time'] = pd.to_datetime(df_filtered['forecasted_entry_time'])\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ids = df_filtered['id'].values\n",
    "\n",
    "pt_gdf = pred_traj_pd.loc[pred_traj_pd['flightID'].isin(relevant_ids)].copy()\n",
    "\n",
    "pt_gdf['time_stamp'] = pd.to_datetime(pt_gdf['time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385bc28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start creating trajectory matrices\n",
      "1308320 has no grid intersection\n",
      "trajectory.csv created\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if \"trajectory.csv\" not in os.listdir(f\"{processed_data_path}/{sector_name}/occupancy/\"):\n",
    "    print(\"start creating trajectory matrices\")\n",
    "    pt_occupancies = []\n",
    "    for id_ , flight in df_filtered.iterrows():\n",
    "        this_matrix = np.zeros(len(grid))\n",
    "        if flight['id'] not in pt_gdf['flightID'].values:\n",
    "            pt_occupancies.append(this_matrix)\n",
    "            print(flight['id'],\"has no grid intersection\")\n",
    "            continue\n",
    "        route = pt_gdf.loc[pt_gdf['flightID'] == flight['id']]['geometry'].values[0]\n",
    "        intersections = grid.intersects(route)\n",
    "        this_matrix += intersections\n",
    "        pt_occupancies.append(this_matrix)\n",
    "    colnames = [\"flight_id\"] + list(range(len(grid)))\n",
    "    pt_occ_df = pd.DataFrame(np.insert(pt_occupancies,0,df_filtered['id'].values,axis=1), columns =colnames)\n",
    "    pt_occ_df.to_csv(f\"{processed_data_path}/{sector_name}/occupancy/trajectory.csv\",index=False)\n",
    "    print(\"trajectory.csv created\")\n",
    "    pt_occ_df\n",
    "else:\n",
    "    print(\"trajectory.csv already existend for sector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc392144",
   "metadata": {},
   "source": [
    "# Occupancy\n",
    "Create the occupancy matrixes at different timepoints (see deltas_from_et). Variable refers to minutes after the expected sector entry of a flight.\n",
    "\n",
    "To recreate the matrices ensure that there is an empty folder occupancy/ in the respective processed_data/sector directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa251a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_at_time(trajectory, timestamp):\n",
    "    last_point = None\n",
    "    for point in trajectory:\n",
    "        eto = datetime.datetime.strptime(point['eto'],\"%Y-%m-%dT%H:%M:%S\")\n",
    "        if eto > timestamp and last_point:\n",
    "            last_eto =  datetime.datetime.strptime(last_point['eto'],\"%Y-%m-%dT%H:%M:%S\")\n",
    "            if eto == last_eto:\n",
    "                continue\n",
    "            factor = (timestamp -last_eto).seconds / (eto - last_eto).seconds\n",
    "            res_lon = last_point['lon'] + factor*(point['lon'] - last_point['lon'])\n",
    "            res_lat = last_point['lat'] + factor*(point['lat'] - last_point['lat'])\n",
    "            return Point(res_lon, res_lat)\n",
    "        else:\n",
    "            last_point = point\n",
    "    return None\n",
    "\n",
    "def find_folder(path, file):\n",
    "    for folder in os.listdir(path):\n",
    "        if not folder.endswith('.zip'):\n",
    "            if file in os.listdir(path+folder):\n",
    "                return path+folder+\"/\"\n",
    "    return \"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9d61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_gdf['entry_time'] = pd.to_datetime(pt_gdf['entry_time'])\n",
    "pt_gdf['time_stamp'] = pd.to_datetime(pt_gdf['time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb313327",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pts_ff = {}\n",
    "for id_ , flight in df_filtered.iterrows():\n",
    "    et = flight['forecasted_entry_time']\n",
    "    possible_pt = pt_gdf.loc[(pt_gdf['entry_time'] > et - datetime.timedelta(minutes = 30)) \n",
    "                             & (pt_gdf['entry_time'] < et + datetime.timedelta(minutes = 30))\n",
    "                            # & (pt_gdf['time_stamp'] < et - timedelta(minutes = buffer))\n",
    "                            & (pt_gdf['flightID'] != flight['id'])]\n",
    "    most_recent_ones = possible_pt.groupby(\"flightID\", as_index = False).max(\"time_stamp\").reset_index()\n",
    "    relevant_pts_ff[flight['id']] = most_recent_ones['flightID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce05e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start creating occupancy matrices\n",
      "4.878762745767673 %\n",
      "9.757525491535347 %\n",
      "14.636288237303019 %\n",
      "19.515050983070694 %\n",
      "24.393813728838367 %\n",
      "29.272576474606037 %\n",
      "34.151339220373714 %\n",
      "39.03010196614139 %\n",
      "43.90886471190906 %\n",
      "48.787627457676734 %\n",
      "53.6663902034444 %\n",
      "58.545152949212074 %\n",
      "63.42391569497975 %\n",
      "68.30267844074743 %\n",
      "73.1814411865151 %\n",
      "78.06020393228277 %\n",
      "82.93896667805043 %\n",
      "87.81772942381812 %\n",
      "92.6964921695858 %\n",
      "97.57525491535347 %\n",
      "finished creating occupancy matrices\n"
     ]
    }
   ],
   "source": [
    "video_occ_path = f\"{processed_data_path}/{sector_name}/occupancy/\"\n",
    "deltas_from_et = [0,5,10]\n",
    "\n",
    "if \"occs\" not in os.listdir(video_occ_path):\n",
    "    print(\"start creating occupancy matrices\")\n",
    "    os.mkdir(f\"{video_occ_path}occs\")\n",
    "    c = 0\n",
    "    point_delta_dict = {}\n",
    "    for id_ , flight in df_filtered.iterrows():\n",
    "        c+=1\n",
    "        folder_path = find_folder(raw_data_path, str(flight['id']) + \".json\")\n",
    "        entry_time = flight['forecasted_entry_time']\n",
    "        point_delta_dict[flight['id']] = {}\n",
    "        for fid_pt in relevant_pts_ff[flight['id']]:\n",
    "            point_delta_dict[flight['id']][fid_pt] = {}\n",
    "            with open(folder_path+ str(fid_pt) +\".json\", 'r') as f:\n",
    "                flight_json = json.load(f)\n",
    "            pt_route = flight_json['predicted_trajectory'][0]['route']\n",
    "            for delta in deltas_from_et:\n",
    "                point = point_at_time(pt_route, entry_time + datetime.timedelta(minutes=delta))\n",
    "                point_delta_dict[flight['id']][fid_pt][delta] = point\n",
    "        if (c%1000)==0:\n",
    "            print(c/len(df_filtered) * 100, \"%\")\n",
    "            all_occs = []\n",
    "            for fid, point_dict in point_delta_dict.items():\n",
    "                occs = []\n",
    "                for delta in deltas_from_et:\n",
    "                    this_delta_occ = np.zeros(100)\n",
    "                    for pt_ids,delta_dict in point_dict.items():\n",
    "                        if delta_dict[delta]:\n",
    "                            this_delta_occ += grid.intersects(delta_dict[delta])\n",
    "                    occs.append(this_delta_occ)\n",
    "                all_occs.append(occs)\n",
    "            all_occs = np.array(all_occs)\n",
    "            np.save(video_occ_path+\"occs/\"+str(c/1000),all_occs)\n",
    "            point_delta_dict = {}\n",
    "    all_occs = []\n",
    "    for fid, point_dict in point_delta_dict.items():\n",
    "        occs = []\n",
    "        for delta in deltas_from_et:\n",
    "            this_delta_occ = np.zeros(100)\n",
    "            for pt_ids,delta_dict in point_dict.items():\n",
    "                if delta_dict[delta]:\n",
    "                    this_delta_occ += grid.intersects(delta_dict[delta])\n",
    "            occs.append(this_delta_occ)\n",
    "        all_occs.append(occs)\n",
    "    all_occs = np.array(all_occs)\n",
    "    np.save(video_occ_path+\"occs/\"+f\"{int(len(df_filtered)//1000)+1}.0\",all_occs)\n",
    "    np.save(video_occ_path+\"ids\", df_filtered['id'].values)\n",
    "    print(\"finished creating occupancy matrices\")\n",
    "else:\n",
    "    print(\"occupancy matrices already exist for the sector. To recreate, delete occs and ids folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada0624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab41e8e-c502-43bb-be46-6e3e15744095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
